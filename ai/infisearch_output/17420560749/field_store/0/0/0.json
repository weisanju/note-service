[[["_relative_fp","可配置的运行块.html"],["title","可配置的运行块.md - AI笔记"],["body","\n    \n        \n        \n\n        \n        \n\n        \n\n        \n        \n\n        \n\n        \n\n            \n                \n                \n                    \n                        "],["body","\n                            \n                        "],["body","\n                        "],["body","\n                            \n                        "],["body","\n                        \n                            "],["body","Light"],["body","\n                            "],["body","Rust"],["body","\n                            "],["body","Coal"],["body","\n                            "],["body","Navy"],["body","\n                            "],["body","Ayu"],["body","\n                        \n                    \n\n                    "],["heading","AI笔记"],["body","\n\n                    \n\n                    \n                \n\n\n                \n                \n\n                \n                    "],["body","\n                        \n\n"],["body","\n"],["body","\n\n"],["headingLink","可配置的runnables"],["heading","可配置的Runnables"],["body","\n"],["body","[TOC]"],["body","\n"],["body","Runnable接口是使用LangChain组件的基础，它在许多组件中都有实现，例如语言模型、输出解析器、检索器、编译后的LangGraph图等。"],["body","\n"],["body","本指南涵盖了Runnable接口的主要概念和方法，它允许开发者以一致和可预测的方式与各种LangChain组件进行交互。"],["body","\n"],["body","相关资源："],["body","\n\n"],["body","Runnable接口API参考提供了Runnable接口及其方法的详细概述。"],["body","\n"],["body","内置的Runnables列表可以在LangChain Core API参考中找到。这些Runnables在使用LangChain表达式语言(LCEL)组合自定义\"链\"时非常有用。"],["body","\n\n"],["headingLink","runnable接口概述"],["heading","Runnable接口概述"],["body","\n"],["body","Runnable方式定义了一个标准接口，使Runnable组件可以："],["body","\n\n"],["body","调用：将单个输入转换为输出。"],["body","\n"],["body","批处理：高效地将多个输入转换为输出。"],["body","\n"],["body","流式处理：输出在生成时进行流式传输。"],["body","\n"],["body","检查：可以访问Runnable的输入、输出和配置的模式信息。"],["body","\n"],["body","组合：多个Runnables可以使用LangChain表达式语言(LCEL)组合在一起，创建复杂的管道。"],["body","\n\n"],["body","请查看LCEL速查表了解一些涉及Runnable接口和LCEL表达式的常见模式。"],["body","\n"],["headingLink","优化的并行执行批处理"],["heading","优化的并行执行(批处理)"],["body","\n"],["body","LangChain Runnables提供了内置的batch（和batch_as_completed）API，允许你并行处理多个输入。"],["body","\n"],["body","当需要处理多个独立输入时，使用这些方法可以显著提高性能，因为处理可以并行进行而不是顺序进行。"],["body","\n"],["body","两种批处理选项是："],["body","\n\n"],["body","batch：并行处理多个输入，返回结果的顺序与输入相同。"],["body","\n"],["body","batch_as_completed：并行处理多个输入，按完成顺序返回结果。结果可能会乱序到达，但每个结果都包含输入索引以便匹配。"],["body","\n\n"],["body","batch和batch_as_completed的默认实现使用线程池执行器并行运行invoke方法。这允许高效的并行执行，而无需用户管理线程，并加速I/O绑定的代码（例如，发出API请求、读取文件等）。对于CPU绑定的操作，它的效果不会那么明显，因为Python中的GIL（全局解释器锁）会阻止真正的并行执行。"],["body","\n"],["body","一些Runnables可能会提供自己的batch和batch_as_completed实现，这些实现针对其特定用例进行了优化（例如，依赖于模型提供商提供的batch API）。"],["body","\n"],["body","\n"],["body","注意：异步版本的abatch和abatch_as_completed依赖于asyncio的gather和as_completed函数来并行运行ainvoke方法。"],["body","\n"],["body","\n"],["body","\n"],["body","提示：当使用batch或batch_as_completed处理大量输入时，用户可能想要控制并行调用的最大数量。这可以通过在RunnableConfig字典中设置max_concurrency属性来实现。更多信息请参见RunnableConfig。聊天模型也有一个内置的速率限制器，可用于控制请求的速率。"],["body","\n"],["body","\n"],["headingLink","异步支持"],["heading","异步支持"],["body","\n"],["body","Runnables暴露了一个异步API，允许使用Python的await语法调用它们。异步方法可以通过\"a\"前缀识别（例如，ainvoke、abatch、astream、abatch_as_completed）。"],["body","\n"],["body","请参阅使用LangChain进行异步编程指南了解更多详情。"],["body","\n"],["headingLink","流式api"],["heading","流式API"],["body","\n"],["body","流式处理对于使基于LLM的应用程序对最终用户感觉响应迅速至关重要。"],["body","\n"],["body","Runnables暴露了以下三个流式API："],["body","\n\n"],["body","同步stream和异步astream：在生成Runnable输出时产生输出。"],["body","\n"],["body","异步astream_events：一个更高级的流式API，允许流式传输中间步骤和最终输出"],["body","\n"],["body","遗留的异步astream_log：一个遗留的流式API，用于流式传输中间步骤和最终输出"],["body","\n\n"],["body","请参阅流式概念指南了解更多关于如何在LangChain中进行流式处理的详情。"],["body","\n"],["headingLink","输入和输出类型"],["heading","输入和输出类型"],["body","\n"],["body","每个Runnable都由输入和输出类型来表征。这些输入和输出类型可以是任何Python对象，并由Runnable本身定义。"],["body","\n"],["body","导致Runnable执行的方法（例如，invoke、batch、stream、astream_events）使用这些输入和输出类型。"],["body","\n\n"],["body","invoke：接受一个输入并返回一个输出。"],["body","\n"],["body","batch：接受输入列表并返回输出列表。"],["body","\n"],["body","stream：接受一个输入并返回一个产生输出的生成器。"],["body","\n\n"],["body","输入类型和输出类型因组件而异："],["body","\n"],["body","组件"],["body","输入类型"],["body","输出类型"],["body","\n"],["body","Prompt"],["body","字典"],["body","PromptValue"],["body","\n"],["body","ChatModel"],["body","字符串、聊天消息列表或PromptValue"],["body","ChatMessage"],["body","\n"],["body","LLM"],["body","字符串、聊天消息列表或PromptValue"],["body","字符串"],["body","\n"],["body","OutputParser"],["body","LLM或ChatModel的输出"],["body","取决于解析器"],["body","\n"],["body","Retriever"],["body","字符串"],["body","文档列表"],["body","\n"],["body","Tool"],["body","字符串或字典，取决于工具"],["body","取决于工具"],["body","\n\n\n"],["body","请参阅各个组件的文档以了解更多关于输入和输出类型及其使用方法的信息。"],["body","\n"],["headingLink","检查模式"],["heading","检查模式"],["body","\n"],["body","\n"],["body","注意：这是一个高级功能，大多数用户不需要。除非你有特定需求要检查Runnable的模式，否则你应该跳过这一节。"],["body","\n"],["body","\n"],["body","在更高级的用例中，你可能想要以编程方式检查Runnable并确定Runnable期望的输入和输出类型。"],["body","\n"],["body","Runnable接口提供了获取Runnable输入和输出类型的JSON Schema的方法，以及输入和输出类型的Pydantic模式。"],["body","\n"],["body","这些API主要在内部用于单元测试，并由LangServe使用，后者使用这些API进行输入验证和生成OpenAPI文档。"],["body","\n"],["body","除了输入和输出类型外，一些Runnables还设置了额外的运行时配置选项。\n有相应的API来获取Runnable的配置选项的Pydantic模式和JSON模式。\n请参见可配置的Runnables部分了解更多信息。"],["body","\n"],["body","方法"],["body","描述"],["body","\n"],["body","get_input_schema"],["body","给出Runnable的输入模式的Pydantic模式。"],["body","\n"],["body","get_output_schema"],["body","给出Runnable的输出模式的Pydantic模式。"],["body","\n"],["body","config_schema"],["body","给出Runnable的配置模式的Pydantic模式。"],["body","\n"],["body","get_input_jsonschema"],["body","给出Runnable的输入模式的JSONSchema。"],["body","\n"],["body","get_output_jsonschema"],["body","给出Runnable的输出模式的JSONSchema。"],["body","\n"],["body","get_config_jsonschema"],["body","给出Runnable的配置模式的JSONSchema。"],["body","\n\n\n"],["headingLink","with_types"],["heading","With_types"],["body","\n"],["body","LangChain将自动尝试根据可用信息推断Runnable的输入和输出类型。"],["body","\n"],["body","目前，这种推断对于使用LCEL组合构建的更复杂的Runnables效果不太好，推断出的输入和/或输出类型可能不正确。在这些情况下，我们建议用户使用with_types方法(API参考)覆盖推断的输入和输出类型。"],["body","\n"],["headingLink","runnableconfig"],["heading","RunnableConfig"],["body","\n"],["body","任何用于执行runnable的方法（例如，invoke、batch、stream、astream_events）都接受第二个参数，称为RunnableConfig(API参考)。这个参数是一个字典，包含将在runnable执行期间在运行时使用的配置。"],["body","\n"],["body","RunnableConfig可以具有以下任何已定义的属性："],["body","\n"],["body","属性"],["body","描述"],["body","\n"],["body","run_name"],["body","用于给定Runnable的名称（不继承）。"],["body","\n"],["body","run_id"],["body","此调用的唯一标识符。子调用将获得自己的唯一运行ID。"],["body","\n"],["body","tags"],["body","此调用和任何子调用的标签。"],["body","\n"],["body","metadata"],["body","此调用和任何子调用的元数据。"],["body","\n"],["body","callbacks"],["body","此调用和任何子调用的回调。"],["body","\n"],["body","max_concurrency"],["body","要进行的最大并行调用数（例如，由batch使用）。"],["body","\n"],["body","recursion_limit"],["body","调用可以递归的最大次数（例如，由返回Runnables的Runnables使用）"],["body","\n"],["body","configurable"],["body","Runnable的可配置属性的运行时值。"],["body","\n\n\n"],["body","向invoke方法传递config的方式如下："],["body","\n"],["body","some_runnable.invoke(  \n   some_input,   \n   config={  \n      'run_name': 'my_run',   \n      'tags': ['tag1', 'tag2'],   \n      'metadata': {'key': 'value'}  \n   }  \n)\n"],["body","\n"],["headingLink","runnableconfig的传播"],["heading","RunnableConfig的传播"],["body","\n"],["body","许多Runnables由其他Runnables组成，重要的是RunnableConfig要传播到Runnable进行的所有子调用。这允许向父Runnable提供运行时配置值，这些值由所有子调用继承。"],["body","\n"],["body","如果不是这样，就不可能设置和传播callbacks或其他配置值，如tags和metadata，这些值预期会被所有子调用继承。"],["body","\n"],["body","创建新的Runnables主要有两种模式："],["body","\n\n"],["body","\n"],["body","使用LangChain表达式语言(LCEL)声明式创建："],["body","\n"],["body","chain = prompt | chat_model | output_parser\n"],["body","\n"],["body","\n"],["body","\n"],["body","使用自定义Runnable（例如，RunnableLambda）或使用@tool装饰器："],["body","\n"],["body","def foo(input):\n    # 注意这里直接使用.invoke()\n    return bar_runnable.invoke(input)\nfoo_runnable = RunnableLambda(foo)\n"],["body","\n"],["body","\n\n"],["body","LangChain将尝试自动传播这两种模式的RunnableConfig。"],["body","\n"],["body","对于处理第二种模式，LangChain依赖于Python的contextvars。"],["body","\n"],["body","在Python 3.11及以上版本中，这是开箱即用的，你不需要做任何特殊操作来将RunnableConfig传播到子调用。"],["body","\n"],["body","在Python 3.9和3.10中，如果你使用异步代码，你需要在调用Runnable时手动传递RunnableConfig。"],["body","\n"],["body","这是由于Python 3.9和3.10中asyncio的任务的限制（不接受context参数）。"],["body","\n"],["body","手动传播RunnableConfig的方式如下："],["body","\n"],["body","async def foo(input, config): # <-- 注意config参数\n    return await bar_runnable.ainvoke(input, config=config)\n      \nfoo_runnable = RunnableLambda(foo)\n"],["body","\n"],["body","\n"],["body","警告：当使用Python 3.10或更低版本并编写异步代码时，RunnableConfig无法自动传播，你需要手动传播！这是在尝试使用astream_events和astream_log流式传输数据时的一个常见陷阱，因为这些方法依赖于正确传播定义在RunnableConfig内的callbacks。"],["body","\n"],["body","\n"],["headingLink","设置自定义运行名称标签和元数据"],["heading","设置自定义运行名称、标签和元数据"],["body","\n"],["body","RunnableConfig字典的run_name、tags和metadata属性可用于为给定的Runnable设置自定义值。"],["body","\n"],["body","run_name是一个字符串，可用于为运行设置自定义名称。此名称将在日志和其他地方用于标识运行。它不会被子调用继承。"],["body","\n"],["body","tags和metadata属性分别是列表和字典，可用于为运行设置自定义标签和元数据。这些值会被子调用继承。"],["body","\n"],["body","使用这些属性对于跟踪和调试运行很有用，因为它们将在LangSmith中作为跟踪属性显示，你可以对其进行过滤和搜索。"],["body","\n"],["body","这些属性还将传播到callbacks，并将在流式API（如astream_events）中作为流中每个事件的一部分出现。"],["body","\n"],["headingLink","设置运行id"],["heading","设置运行ID"],["body","\n"],["body","\n"],["body","注意：这是一个高级功能，大多数用户不需要。"],["body","\n"],["body","\n"],["body","你可能需要为给定的运行设置自定义run_id，以便以后引用它或将其与其他系统关联。"],["body","\n"],["body","run_id必须是有效的UUID字符串，并且对每次运行都是唯一的。它用于标识父运行，子类将自动获得自己的唯一运行ID。"],["body","\n"],["body","要设置自定义run_id，你可以在调用Runnable时在config字典中将其作为键值对传递："],["body","\n"],["body","import uuid\n  \nrun_id = uuid.uuid4()\n  \nsome_runnable.invoke(\n   some_input,   \n   config={\n      'run_id': run_id\n   }\n)\n  \n# 使用run_id做一些事情\n"],["body","\n"],["headingLink","设置递归限制"],["heading","设置递归限制"],["body","\n"],["body","\n"],["body","注意：这是一个高级功能，大多数用户不需要。"],["body","\n"],["body","\n"],["body","一些Runnables可能会返回其他Runnables，如果处理不当，这可能导致无限递归。为防止这种情况，你可以在RunnableConfig字典中设置recursion_limit。这将限制Runnable可以递归的次数。"],["body","\n"],["headingLink","设置最大并发数"],["heading","设置最大并发数"],["body","\n"],["body","如果使用batch或batch_as_completed方法，你可以在RunnableConfig字典中设置max_concurrency属性来控制要进行的最大并行调用数。当你想要限制并行调用的数量以防止服务器或API过载时，这很有用。"],["body","\n"],["body","\n"],["body","提示：如果你试图限制聊天模型的请求数量，你可以使用内置的速率限制器而不是设置max_concurrency，这将更有效。"],["body","\n"],["body","参见如何处理速率限制指南了解更多信息。"],["body","\n"],["body","\n"],["headingLink","设置可配置项"],["heading","设置可配置项"],["body","\n"],["body","configurable字段用于为Runnable的可配置属性传递运行时值。"],["body","\n"],["body","它在LangGraph中与LangGraph持久性和内存一起经常使用。"],["body","\n"],["body","它在RunnableWithMessageHistory中用于类似的目的，以指定session_id/conversation_id来跟踪对话历史。"],["body","\n"],["body","此外，你可以使用它来指定要传递给他们创建的任何可配置Runnable的任何自定义配置选项。"],["body","\n"],["headingLink","设置回调"],["heading","设置回调"],["body","\n"],["body","使用此选项在运行时为runnable配置callbacks。回调将传递给runnable进行的所有子调用。"],["body","\n"],["body","some_runnable.invoke(\n   some_input,\n   {\n      \"callbacks\": [\n         SomeCallbackHandler(),\n         AnotherCallbackHandler(),\n      ]\n   }\n)\n"],["body","\n"],["body","请阅读回调概念指南了解更多关于如何在LangChain中使用回调的信息。"],["body","\n"],["body","\n"],["body","重要提示：如果你在异步环境中使用Python 3.9或3.10，在某些情况下你必须手动将RunnableConfig传播到子调用。请参见传播RunnableConfig部分了解更多信息。"],["body","\n"],["body","\n"],["headingLink","从函数创建runnable"],["heading","从函数创建runnable"],["body","\n"],["body","你可能需要创建一个运行任意逻辑的自定义Runnable。如果使用LangChain表达式语言(LCEL)组合多个Runnables，并且需要在其中一个步骤中添加自定义处理逻辑，这特别有用。"],["body","\n"],["body","有两种方法可以从函数创建自定义Runnable："],["body","\n\n"],["body","RunnableLambda：用于不需要流式处理的简单转换。"],["body","\n"],["body","RunnableGenerator：用于需要流式处理的更复杂转换。"],["body","\n\n"],["body","参见如何运行自定义函数指南了解更多关于如何使用RunnableLambda和RunnableGenerator的信息。"],["body","\n"],["body","\n"],["body","重要提示：用户不应尝试子类化Runnables来创建新的自定义Runnable。这比简单地使用RunnableLambda或RunnableGenerator要复杂得多，也更容易出错。"],["body","\n"],["body","\n"],["headingLink","可配置的runnables-1"],["heading","可配置的runnables"],["body","\n"],["body","有时你可能想要尝试，甚至向最终用户公开使用Runnable的多种不同方式。这可能涉及调整聊天模型中的温度等参数，甚至在不同的聊天模型之间切换。"],["body","\n"],["body","为了简化这个过程，Runnable接口提供了两种在运行时创建可配置Runnables的方法："],["body","\n\n"],["body","configurable_fields：此方法允许你配置Runnable中的特定属性。例如，聊天模型的temperature属性。"],["body","\n"],["body","configurable_alternatives：此方法使你能够指定可以在运行时运行的替代Runnables。例如，你可以指定可以使用的不同聊天模型列表。"],["body","\n\n"],["body","参见如何配置运行时链内部指南了解更多关于如何配置运行时链内部的信息。"],["body","\n\n\n\n                    "],["body","\n\n                    \n                \n            \n\n            \n\n        \n\n\n\n\n        \n\n\n\n        \n        \n        \n\n        \n\n\n    \n    \n\n"]],[["_relative_fp","index.html"],["title","AI使用场景整理.md - AI笔记"],["body","\n    \n        \n        \n\n        \n        \n\n        \n\n        \n        \n\n        \n\n        \n\n            \n                \n                \n                    \n                        "],["body","\n                            \n                        "],["body","\n                        "],["body","\n                            \n                        "],["body","\n                        \n                            "],["body","Light"],["body","\n                            "],["body","Rust"],["body","\n                            "],["body","Coal"],["body","\n                            "],["body","Navy"],["body","\n                            "],["body","Ayu"],["body","\n                        \n                    \n\n                    "],["heading","AI笔记"],["body","\n\n                    \n\n                    \n                \n\n\n                \n                \n\n                \n                    "],["body","\n                        \n\n"],["body","\n"],["body","\n\n\n"],["body","知识库"],["body","\n"],["body","答题助手"],["body","\n"],["body","自动阅读助手"],["body","\n"],["body","类Follow：RSS自主抓取"],["body","\n"],["body","整网站爬取 -> MARKDOWN化"],["body","\n"],["body","任意文档全文翻译成markdown\n\n"],["body","loader"],["body","\n"],["body","递归翻译"],["body","\n\n"],["body","\n\n\n\n\n                    "],["body","\n\n                    \n                \n            \n\n            \n\n        \n\n\n\n\n        \n\n\n\n        \n        \n        \n\n        \n\n\n    \n    \n\n"]],[["_relative_fp","AI使用场景整理.html"],["title","AI使用场景整理.md - AI笔记"],["body","\n    \n        \n        \n\n        \n        \n\n        \n\n        \n        \n\n        \n\n        \n\n            \n                \n                \n                    \n                        "],["body","\n                            \n                        "],["body","\n                        "],["body","\n                            \n                        "],["body","\n                        \n                            "],["body","Light"],["body","\n                            "],["body","Rust"],["body","\n                            "],["body","Coal"],["body","\n                            "],["body","Navy"],["body","\n                            "],["body","Ayu"],["body","\n                        \n                    \n\n                    "],["heading","AI笔记"],["body","\n\n                    \n\n                    \n                \n\n\n                \n                \n\n                \n                    "],["body","\n                        \n\n"],["body","\n"],["body","\n\n\n"],["body","知识库"],["body","\n"],["body","答题助手"],["body","\n"],["body","自动阅读助手"],["body","\n"],["body","类Follow：RSS自主抓取"],["body","\n"],["body","整网站爬取 -> MARKDOWN化"],["body","\n"],["body","任意文档全文翻译成markdown\n\n"],["body","loader"],["body","\n"],["body","递归翻译"],["body","\n\n"],["body","\n\n\n\n\n                    "],["body","\n\n                    \n                \n            \n\n            \n\n        \n\n\n\n\n        \n\n\n\n        \n        \n        \n\n        \n\n\n    \n    \n\n"]],[["_relative_fp","AI资源整理.html"],["title","AI资源整理.md - AI笔记"],["body","\n    \n        \n        \n\n        \n        \n\n        \n\n        \n        \n\n        \n\n        \n\n            \n                \n                \n                    \n                        "],["body","\n                            \n                        "],["body","\n                        "],["body","\n                            \n                        "],["body","\n                        \n                            "],["body","Light"],["body","\n                            "],["body","Rust"],["body","\n                            "],["body","Coal"],["body","\n                            "],["body","Navy"],["body","\n                            "],["body","Ayu"],["body","\n                        \n                    \n\n                    "],["heading","AI笔记"],["body","\n\n                    \n\n                    \n                \n\n\n                \n                \n\n                \n                    "],["body","\n                        \n\n"],["body","\n"],["body","\n\n"],["headingLink","api-endpoint"],["heading","API ENDPOINT"],["body","\n\n"],["body","\n"],["body","nvidia：https://build.nvidia.com/"],["body","\n"],["body","\n"],["body","\n"],["body","硅基流动：https://cloud.siliconflow.cn/"],["body","\n"],["body","\n"],["body","\n"],["body","百炼：https://bailian.console.aliyun.com/#/home"],["body","\n"],["body","\n\n\n\n\n                    "],["body","\n\n                    \n                \n            \n\n            \n\n        \n\n\n\n\n        \n\n\n\n        \n        \n        \n\n        \n\n\n    \n    \n\n"]],[["_relative_fp","languagechain/1.prompts.html"],["title","prompts.md - AI笔记"],["body","\n    \n        \n        \n\n        \n        \n\n        \n\n        \n        \n\n        \n\n        \n\n            \n                \n                \n                    \n                        "],["body","\n                            \n                        "],["body","\n                        "],["body","\n                            \n                        "],["body","\n                        \n                            "],["body","Light"],["body","\n                            "],["body","Rust"],["body","\n                            "],["body","Coal"],["body","\n                            "],["body","Navy"],["body","\n                            "],["body","Ayu"],["body","\n                        \n                    \n\n                    "],["heading","AI笔记"],["body","\n\n                    \n\n                    \n                \n\n\n                \n                \n\n                \n                    "],["body","\n                        \n\n"],["body","\n"],["body","\n\n"],["headingLink","langchain-提示模板"],["heading","LangChain 提示模板"],["body","\n"],["body","[TOC]"],["body","\n"],["body","LangChain 提示模板"],["body","\n"],["headingLink","1-基本模板创建与使用"],["heading","1. 基本模板创建与使用"],["body","\n"],["body","PromptTemplate支持多种创建方式，方便灵活构建提示模板："],["body","\n"],["body","from langchain_core.prompts import PromptTemplate\n\n# 直接从模板字符串创建\ntemplate = PromptTemplate.from_template(\"你是一位{role}，请{action}关于{topic}的内容。\")\n\n# 完整构造方式\nprompt = PromptTemplate(\n    template=\"为{product}写一个{word_count}字的广告文案，强调其{feature}特性。\",\n    input_variables=[\"product\", \"word_count\", \"feature\"]\n)\n\n# 使用模板\nformatted_prompt = prompt.format(\n    product=\"智能手表\",\n    word_count=\"100\",\n    feature=\"健康监测\"\n)\n"],["body","\n"],["headingLink","2-部分格式化partial-formatting"],["heading","2. 部分格式化(Partial Formatting)"],["body","\n"],["body","支持分阶段设置变量，类似于函数的部分应用："],["body","\n"],["headingLink","21-字符串部分格式化"],["heading","2.1 字符串部分格式化"],["body","\n"],["body","from langchain_core.prompts import PromptTemplate\n\n# 创建带有两个变量的模板\ntemplate = PromptTemplate.from_template(\"为{product}写一个关于{feature}的广告语\")\n\n# 部分格式化，只设置一个变量\npartial_prompt = template.partial(product=\"智能手表\")\n\n# 稍后设置其他变量\nfinal_prompt = partial_prompt.format(feature=\"健康监测\")\n"],["body","\n"],["headingLink","22-函数式变量"],["heading","2.2 函数式变量"],["body","\n"],["body","支持使用函数作为变量值，在格式化时动态生成内容："],["body","\n"],["body","from datetime import datetime\n\n# 定义返回当前时间的函数\ndef get_time():\n    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n\n# 使用函数作为变量值\nprompt = PromptTemplate(\n    template=\"当前时间是: {time}\\n分析以下数据: {data}\",\n    input_variables=[\"data\"],\n    partial_variables={\"time\": get_time}\n)\n"],["body","\n"],["headingLink","3-聊天模板chatprompttemplate"],["heading","3. 聊天模板(ChatPromptTemplate)"],["body","\n"],["body","专为对话模型设计的模板，支持构建多轮对话："],["body","\n"],["body","from langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.messages import SystemMessage, HumanMessage\n\n# 从消息列表创建聊天模板\nchat_prompt = ChatPromptTemplate.fromMessages([\n    [\"system\", \"你是一位专业的{profession}，擅长{expertise}。\"],\n    [\"human\", \"请回答关于{topic}的问题：{question}\"]\n])\n\n# 格式化聊天模板\nmessages = chat_prompt.format_messages(\n    profession=\"AI研究员\",\n    expertise=\"机器学习\",\n    topic=\"大语言模型\",\n    question=\"什么是提示工程？\"\n)\n"],["body","\n"],["headingLink","4-消息占位符messagesplaceholder"],["heading","4. 消息占位符(MessagesPlaceholder)"],["body","\n"],["body","允许在模板特定位置插入一组消息，特别适用于聊天历史："],["body","\n"],["body","from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\nfrom langchain_core.messages import HumanMessage, AIMessage\n\n# 创建带有消息占位符的聊天模板\nchat_prompt = ChatPromptTemplate.fromMessages([\n    [\"system\", \"你是一位专业助手\"],\n    MessagesPlaceholder(\"chat_history\"),  # 会被一组消息替换\n    [\"human\", \"回答关于{topic}的问题\"]\n])\n\n# 使用模板\nformatted_prompt = chat_prompt.invoke({\n    \"topic\": \"人工智能\",\n    \"chat_history\": [\n        HumanMessage(content=\"什么是机器学习？\"),\n        AIMessage(content=\"机器学习是AI的一个分支，研究如何让计算机从数据中学习\")\n    ]\n})\n"],["body","\n"],["headingLink","5-少样本学习模板fewshotprompttemplate"],["heading","5. 少样本学习模板(FewShotPromptTemplate)"],["body","\n"],["body","支持在提示中包含示例，帮助模型理解任务："],["body","\n"],["body","from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate\n\n# 定义示例\nexamples = [\n    {\"input\": \"我感觉很难过\", \"output\": \"听起来你正在经历一些困难的情绪。能告诉我更多吗？\"},\n    {\"input\": \"我不知道如何解决这个问题\", \"output\": \"让我们一步步思考这个问题。能详细描述一下吗？\"}\n]\n\n# 创建示例格式化模板\nexample_prompt = PromptTemplate(\n    input_variables=[\"input\", \"output\"],\n    template=\"用户: {input}\\n助手: {output}\"\n)\n\n# 创建少样本学习模板\nfew_shot_prompt = FewShotPromptTemplate(\n    examples=examples,\n    example_prompt=example_prompt,\n    prefix=\"你是一个有帮助的助手。以下是一些对话示例：\",\n    suffix=\"用户: {input}\\n助手:\",\n    input_variables=[\"input\"],\n    example_separator=\"\\n\\n\"\n)\n\n# 使用模板\nresponse = few_shot_prompt.format(input=\"我最近工作压力很大\")\n"],["body","\n"],["headingLink","6-示例选择器exampleselectors"],["heading","6. 示例选择器(ExampleSelectors)"],["body","\n"],["body","智能选择最相关的示例以优化少样本学习效果："],["body","\n"],["headingLink","61-相似度选择器"],["heading","6.1 相似度选择器"],["body","\n"],["body","from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\nfrom langchain.vectorstores import FAISS\nfrom langchain.embeddings import OpenAIEmbeddings\n\n# 创建基于相似度的选择器\nexample_selector = SemanticSimilarityExampleSelector.from_examples(\n    examples,\n    OpenAIEmbeddings(),\n    FAISS,\n    k=2  # 选择2个最相似的示例\n)\n\n# 使用选择器创建少样本模板\nsimilarity_prompt = FewShotPromptTemplate(\n    example_selector=example_selector,\n    example_prompt=example_prompt,\n    prefix=\"你是一位顾问，请根据以下示例回答问题:\",\n    suffix=\"问题: {question}\\n回答:\",\n    input_variables=[\"question\"]\n)\n"],["body","\n"],["headingLink","62-长度选择器"],["heading","6.2 长度选择器"],["body","\n"],["body","from langchain.prompts.example_selector import LengthBasedExampleSelector\n\n# 基于长度选择示例\nlength_selector = LengthBasedExampleSelector(\n    examples=examples,\n    example_prompt=example_prompt,\n    max_length=1000  # 总示例长度不超过1000字符\n)\n\nlength_prompt = FewShotPromptTemplate(\n    example_selector=length_selector,\n    example_prompt=example_prompt,\n    prefix=\"以下是一些例子：\",\n    suffix=\"新问题: {question}\\n回答:\",\n    input_variables=[\"question\"]\n)\n"],["body","\n"],["headingLink","63-最大边际相关性mmr选择器"],["heading","6.3 最大边际相关性(MMR)选择器"],["body","\n"],["body","from langchain.prompts.example_selector import MaximalMarginalRelevanceExampleSelector\n\n# 使用MMR算法选择多样化且相关的示例\nmmr_selector = MaximalMarginalRelevanceExampleSelector.from_examples(\n    examples,\n    OpenAIEmbeddings(),\n    FAISS,\n    k=2\n)\n"],["body","\n"],["headingLink","7-管道提示模板pipelineprompttemplate"],["heading","7. 管道提示模板(PipelinePromptTemplate)"],["body","\n"],["body","组合多个模板组件，构建复杂提示流程："],["body","\n"],["body","from langchain_core.prompts import PipelinePromptTemplate, PromptTemplate\n\n# 定义多个模板组件\nfull_template = \"\"\"\n{introduction}\n\n{examples}\n\n{question}\n\"\"\"\n\nintroduction_template = PromptTemplate.from_template(\n    \"你是一位专业的{profession}。你的任务是{task}。\"\n)\nexamples_template = PromptTemplate.from_template(\n    \"这里有一些例子:\\n{examples_text}\"\n)\nquestion_template = PromptTemplate.from_template(\n    \"现在，请回答以下问题:\\n{question_text}\"\n)\n\n# 创建管道模板\npipeline_prompts = [\n    (\"introduction\", introduction_template),\n    (\"examples\", examples_template),\n    (\"question\", question_template)\n]\n\npipeline_prompt = PipelinePromptTemplate(\n    final_prompt=PromptTemplate.from_template(full_template),\n    pipeline_prompts=pipeline_prompts\n)\n\n# 使用管道模板\nformatted_prompt = pipeline_prompt.format(\n    profession=\"数学教师\",\n    task=\"解释复杂的数学概念\",\n    examples_text=\"例子1: ...\\n例子2: ...\",\n    question_text=\"请解释线性代数的基本概念\"\n)\n"],["body","\n"],["headingLink","8-与llm链集成"],["heading","8. 与LLM链集成"],["body","\n"],["body","将提示模板无缝集成到LLM处理链中："],["body","\n"],["body","from langchain_core.prompts import PromptTemplate\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_openai import ChatOpenAI\n\n# 创建提示模板\nprompt = PromptTemplate.from_template(\"为{product}写一个广告语，强调{feature}特性。\")\n\n# 创建LLM链\nmodel = ChatOpenAI()\nchain = prompt | model | StrOutputParser()\n\n# 使用链\nresult = chain.invoke({\n    \"product\": \"智能手表\",\n    \"feature\": \"健康监测\"\n})\n"],["body","\n"],["headingLink","9-输出解析器集成"],["heading","9. 输出解析器集成"],["body","\n"],["body","与输出解析器结合，将LLM输出转换为结构化数据："],["body","\n"],["body","from langchain_core.output_parsers import JsonOutputParser\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_openai import ChatOpenAI\n\n# 定义输出架构\nparser = JsonOutputParser(pydantic_object={\n    \"properties\": {\n        \"name\": {\"type\": \"string\"},\n        \"age\": {\"type\": \"integer\"},\n        \"interests\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n    }\n})\n\n# 创建带解析器的模板\nprompt = PromptTemplate(\n    template=\"生成一个关于{topic}的人物资料\\n{format_instructions}\",\n    input_variables=[\"topic\"],\n    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n)\n\n# 使用模板和解析器\nmodel = ChatOpenAI()\nchain = prompt | model | parser\nresult = chain.invoke({\"topic\": \"人工智能研究员\"})\n"],["body","\n"],["headingLink","10-异步支持和事件流"],["heading","10. 异步支持和事件流"],["body","\n"],["body","支持异步处理和流式响应："],["body","\n"],["body","from langchain_core.prompts import PromptTemplate\nfrom langchain_openai import ChatOpenAI\n\n# 异步格式化\nasync def async_format():\n    template = PromptTemplate.from_template(\"分析{query}的结果\")\n    return await template.aformat(query=\"市场数据\")\n\n# 流式响应处理\nasync def stream_response():\n    prompt = PromptTemplate.from_template(\"详细解释{topic}\")\n    model = ChatOpenAI(streaming=True)\n    chain = prompt | model\n    \n    async for chunk in chain.astream({\"topic\": \"量子计算\"}):\n        print(chunk.content, end=\"\", flush=True)\n"],["body","\n"],["headingLink","11-模板保存和加载"],["heading","11. 模板保存和加载"],["body","\n"],["body","支持将模板保存到文件和从文件加载："],["body","\n"],["body","from langchain_core.prompts import PromptTemplate\n\n# 创建模板\nprompt = PromptTemplate.from_template(\"为{product}写一个广告语\")\n\n# 保存模板到文件\nprompt.save(\"product_ad_prompt.json\")\n\n# 从文件加载模板\nloaded_prompt = PromptTemplate.from_file(\"product_ad_prompt.json\")\n"],["body","\n"],["headingLink","12-模板验证"],["heading","12. 模板验证"],["body","\n"],["body","自动验证模板中的变量与声明的输入变量一致性："],["body","\n"],["body","from langchain_core.prompts import PromptTemplate\n\n# 创建带验证的模板\ntry:\n    # 这会失败，因为模板中有未声明的变量\n    invalid_prompt = PromptTemplate(\n        template=\"Hello {name}, welcome to {platform}!\",\n        input_variables=[\"name\"],\n        validate_template=True\n    )\nexcept ValueError as e:\n    print(f\"验证错误: {e}\")\n\n# 正确的模板\nvalid_prompt = PromptTemplate(\n    template=\"Hello {name}, welcome to {platform}!\",\n    input_variables=[\"name\", \"platform\"],\n    validate_template=True\n)\n"],["body","\n"],["headingLink","13-可配置字段和替代项"],["heading","13. 可配置字段和替代项"],["body","\n"],["body","支持定义可配置字段和替代实现："],["body","\n"],["body","from langchain_core.prompts import PromptTemplate\n\n# 创建带可配置字段的模板\ntemplate = PromptTemplate.from_template(\"你是一位{role}\")\n\n# 定义可配置字段\nconfigurable_template = template.configurable_fields(\n    role={\"type\": \"string\", \"description\": \"助手的角色\"}\n)\n\n# 定义替代实现\nalternative_templates = {\n    \"医生\": PromptTemplate.from_template(\"你是一位专业医生，擅长诊断和治疗疾病\"),\n    \"教师\": PromptTemplate.from_template(\"你是一位有经验的教师，擅长解释复杂概念\")\n}\n\nconfigurable_with_alternatives = template.configurable_alternatives(\n    role=alternative_templates\n)\n"],["body","\n"],["headingLink","14-与runnable接口集成"],["heading","14. 与Runnable接口集成"],["body","\n"],["body","支持与LangChain的Runnable接口无缝集成，便于组合和流程控制："],["body","\n"],["body","from langchain_core.prompts import PromptTemplate\nfrom langchain_core.runnables import RunnablePassthrough\n\n# 创建基本提示模板\ntemplate = PromptTemplate.from_template(\"分析以下数据: {data}\")\n\n# 使用Runnable接口构建处理流程\nchain = {\"data\": RunnablePassthrough()} | template\n\n# 运行链\nresult = chain.invoke(\"这是一些需要分析的数据\")\n"],["body","\n\n\n\n                    "],["body","\n\n                    \n                \n            \n\n            \n\n        \n\n\n\n\n        \n\n\n\n        \n        \n        \n\n        \n\n\n    \n    \n\n"]],[["_relative_fp","languagechain/README.html"],["title","languagechain - AI笔记"],["body","\n    \n        \n        \n\n        \n        \n\n        \n\n        \n        \n\n        \n\n        \n\n            \n                \n                \n                    \n                        "],["body","\n                            \n                        "],["body","\n                        "],["body","\n                            \n                        "],["body","\n                        \n                            "],["body","Light"],["body","\n                            "],["body","Rust"],["body","\n                            "],["body","Coal"],["body","\n                            "],["body","Navy"],["body","\n                            "],["body","Ayu"],["body","\n                        \n                    \n\n                    "],["heading","AI笔记"],["body","\n\n                    \n\n                    \n                \n\n\n                \n                \n\n                \n                    "],["body","\n                        \n\n"],["body","\n"],["body","\n\n"],["headingLink","langchain-概念指南"],["heading","LangChain 概念指南"],["body","\n"],["body","\n"],["body","本指南提供了 LangChain 框架和 AI 应用程序背后关键概念的解释。"],["body","\n"],["body","我们建议您在深入概念指南之前先学习至少一个教程。这将提供实用的上下文，使您更容易理解这里讨论的概念。"],["body","\n"],["body","概念指南不涵盖分步说明或特定实现示例 — 这些内容可在操作指南和教程中找到。有关详细参考资料，请参阅 API 参考。"],["body","\n"],["headingLink","高级概述"],["heading","高级概述"],["body","\n\n"],["body","为什么选择 LangChain？: LangChain 提供的价值概述。"],["body","\n"],["body","架构: LangChain 生态系统中的包组织方式。"],["body","\n\n"],["headingLink","核心概念"],["heading","核心概念"],["body","\n\n"],["body","聊天模型 (Chat models): 通过聊天 API 暴露的 LLM，处理消息序列作为输入并输出一条消息。"],["body","\n"],["body","消息 (Messages): 聊天模型中的通信单元，用于表示模型输入和输出。"],["body","\n"],["body","聊天历史 (Chat history): 表示为消息序列的对话，在用户消息和模型响应之间交替。"],["body","\n"],["body","工具 (Tools): 具有相关模式的函数，定义了函数名称、描述及其接受的参数。"],["body","\n"],["body","工具调用 (Tool calling): 一种聊天模型 API，接受工具模式和消息作为输入，并在输出消息中返回这些工具的调用。"],["body","\n"],["body","结构化输出 (Structured output): 使聊天模型以结构化格式（如匹配给定模式的 JSON）响应的技术。"],["body","\n"],["body","记忆 (Memory): 关于对话的持久化信息，可用于未来对话。"],["body","\n"],["body","多模态 (Multimodality): 处理不同形式数据（如文本、音频、图像和视频）的能力。"],["body","\n"],["body","可运行接口 (Runnable interface): 许多 LangChain 组件和 LangChain 表达语言的基础抽象。"],["body","\n"],["body","流式传输 (Streaming): LangChain 流式 API，用于在生成结果时显示。"],["body","\n"],["body","LangChain 表达语言 (LCEL): 用于编排 LangChain 组件的语法，对简单应用最有用。"],["body","\n"],["body","文档加载器 (Document loaders): 将来源加载为文档列表。"],["body","\n"],["body","检索 (Retrieval): 信息检索系统可以响应查询从数据源中检索结构化或非结构化数据。"],["body","\n"],["body","文本分割器 (Text splitters): 将长文本分割成更小的块，以便单独索引，实现精细检索。"],["body","\n"],["body","嵌入模型 (Embedding models): 将数据（如文本或图像）表示在向量空间中的模型。"],["body","\n"],["body","向量存储 (Vector stores): 存储向量及相关元数据并高效搜索。"],["body","\n"],["body","检索器 (Retriever): 响应查询从知识库返回相关文档的组件。"],["body","\n"],["body","检索增强生成 (RAG): 通过将语言模型与外部知识库结合来增强它们的技术。"],["body","\n"],["body","代理 (Agents): 使用语言模型选择要采取的操作序列。代理可以通过工具与外部资源交互。"],["body","\n"],["body","提示模板 (Prompt templates): 用于分解模型\"提示\"（通常是消息序列）的静态部分的组件。对于序列化、版本控制和重用这些静态部分很有用。"],["body","\n"],["body","输出解析器 (Output parsers): 负责接收模型输出并将其转换为更适合下游任务的格式。在工具调用和结构化输出普遍可用之前，输出解析器主要很有用。"],["body","\n"],["body","少样本提示 (Few-shot prompting): 通过在提示中提供任务的几个示例来提高模型性能的技术。"],["body","\n"],["body","示例选择器 (Example selectors): 用于根据给定输入从数据集中选择最相关的示例。示例选择器在少样本提示中用于为提示选择示例。"],["body","\n"],["body","异步编程 (Async programming): 在异步上下文中使用 LangChain 应了解的基础知识。"],["body","\n"],["body","回调 (Callbacks): 回调允许在内置组件中执行自定义辅助代码。在 LangChain 中，回调用于流式传输 LLM 的输出、跟踪应用程序的中间步骤等。"],["body","\n"],["body","跟踪 (Tracing): 记录应用程序从输入到输出所经过步骤的过程。跟踪对于调试和诊断复杂应用程序中的问题至关重要。"],["body","\n"],["body","评估 (Evaluation): 评估 AI 应用程序性能和有效性的过程。包括根据预定义标准或基准测试模型响应，确保其达到所需质量标准并满足预期目的。此过程对于构建可靠的应用程序至关重要。"],["body","\n"],["body","测试 (Testing): 验证集成或应用程序组件按预期工作的过程。测试对于确保应用程序行为正确且代码库更改不会引入新错误至关重要。"],["body","\n\n"],["headingLink","术语表"],["heading","术语表"],["body","\n\n"],["body","AI 消息块 (AIMessageChunk): AI 消息的部分响应。在从聊天模型流式传输响应时使用。"],["body","\n"],["body","AI 消息 (AIMessage): 表示来自 AI 模型的完整响应。"],["body","\n"],["body","astream_events: 从 LCEL 链中流式传输细粒度信息。"],["body","\n"],["body","基础工具 (BaseTool): LangChain 中所有工具的基类。"],["body","\n"],["body","批处理 (batch): 用于使用批量输入执行可运行对象。"],["body","\n"],["body","绑定工具 (bind_tools): 允许模型与工具交互。"],["body","\n"],["body","缓存 (Caching): 存储结果以避免对聊天模型的冗余调用。"],["body","\n"],["body","聊天模型 (Chat models): 处理多种数据模态的聊天模型。"],["body","\n"],["body","可配置可运行对象 (Configurable runnables): 创建可配置的可运行对象。"],["body","\n"],["body","上下文窗口 (Context window): 聊天模型可以处理的最大输入大小。"],["body","\n"],["body","对话模式 (Conversation patterns): 聊天交互中的常见模式。"],["body","\n"],["body","文档 (Document): LangChain 对文档的表示。"],["body","\n"],["body","嵌入模型 (Embedding models): 为各种数据类型生成向量嵌入的模型。"],["body","\n"],["body","人类消息 (HumanMessage): 表示来自人类用户的消息。"],["body","\n"],["body","注入状态 (InjectedState): 注入到工具函数中的状态。"],["body","\n"],["body","注入存储 (InjectedStore): 可以注入到工具中用于数据持久化的存储。"],["body","\n"],["body","注入工具参数 (InjectedToolArg): 向工具函数注入参数的机制。"],["body","\n"],["body","输入和输出类型 (input and output types): 在可运行对象中用于输入和输出的类型。"],["body","\n"],["body","集成包 (Integration packages): 与 LangChain 集成的第三方包。"],["body","\n"],["body","集成测试 (Integration tests): 验证组件之间交互正确性的测试，通常在访问支持集成的底层 API 的情况下运行。"],["body","\n"],["body","调用 (invoke): 调用可运行对象的标准方法。"],["body","\n"],["body","JSON 模式 (JSON mode): 以 JSON 格式返回响应。"],["body","\n"],["body","langchain-community: LangChain 的社区驱动组件。"],["body","\n"],["body","langchain-core: 核心 langchain 包。包括基础接口和内存中实现。"],["body","\n"],["body","langchain: 用于更高级组件的包（例如，一些预构建的链）。"],["body","\n"],["body","langgraph: LangChain 的强大编排层。用于构建复杂的管道和工作流。"],["body","\n"],["body","langserve: 用于将 LangChain 可运行对象部署为 REST 端点。使用 FastAPI。主要适用于 LangChain 可运行对象，目前不与 LangGraph 集成。"],["body","\n"],["body","LLMs (legacy): 较旧的语言模型，接受字符串作为输入并返回字符串作为输出。"],["body","\n"],["body","管理聊天历史 (Managing chat history): 维护和管理聊天历史的技术。"],["body","\n"],["body","OpenAI 格式 (OpenAI format): OpenAI 的聊天模型消息格式。"],["body","\n"],["body","RunnableConfig 传播 (Propagation of RunnableConfig): 通过可运行对象传播配置。如果使用 python 3.9、3.10 和异步，请阅读此内容。"],["body","\n"],["body","速率限制 (rate-limiting): 聊天模型的客户端速率限制。"],["body","\n"],["body","移除消息 (RemoveMessage): 用于从聊天历史中删除消息的抽象，主要在 LangGraph 中使用。"],["body","\n"],["body","角色 (role): 表示聊天消息的角色（例如，用户、助手）。"],["body","\n"],["body","可运行配置 (RunnableConfig): 用于向可运行对象传递运行时信息（例如，run_name、run_id、tags、metadata、max_concurrency、recursion_limit、configurable）。"],["body","\n"],["body","聊天模型的标准参数 (Standard parameters for chat models): 参数如 API 密钥、temperature 和 max_tokens。"],["body","\n"],["body","标准测试 (Standard tests): 所有集成必须通过的一组定义的单元和集成测试。"],["body","\n"],["body","流 (stream): 用于从可运行对象或图表流式传输输出。"],["body","\n"],["body","标记化 (Tokenization): 将数据转换为标记并反之亦然的过程。"],["body","\n"],["body","标记 (Tokens): 语言模型在底层读取、处理和生成的基本单位。"],["body","\n"],["body","工具构件 (Tool artifacts): 向工具输出添加不会发送给模型但可用于下游处理的构件。"],["body","\n"],["body","工具绑定 (Tool binding): 将工具绑定到模型。"],["body","\n"],["body","@tool: 在 LangChain 中创建工具的装饰器。"],["body","\n"],["body","工具包 (Toolkits): 可以一起使用的工具集合。"],["body","\n"],["body","工具消息 (ToolMessage): 表示包含工具执行结果的消息。"],["body","\n"],["body","单元测试 (Unit tests): 验证单个组件正确性的测试，在隔离环境中运行，不访问互联网。"],["body","\n"],["body","向量存储 (Vector stores): 专门用于存储和高效搜索向量嵌入的数据存储。"],["body","\n"],["body","with_structured_output: 一个辅助方法，用于原生支持工具调用的聊天模型，以获取匹配通过 Pydantic、JSON 模式或函数指定的给定模式的结构化输出。"],["body","\n"],["body","with_types: 覆盖可运行对象的输入和输出类型的方法。在使用复杂的 LCEL 链并使用 LangServe 部署时很有用。"],["body","\n\n"],["body","\n"],["headingLink","导航"],["heading","导航"],["body","\n\n"],["body","上一页：如何创建和查询向量存储"],["body","\n"],["body","下一页：代理"],["body","\n\n\n\n\n                    "],["body","\n\n                    \n                \n            \n\n            \n\n        \n\n\n\n\n        \n\n\n\n        \n        \n        \n\n        \n\n\n    \n    \n\n"]],[["_relative_fp","languagechain/2.memory.html"],["title","memory.md - AI笔记"],["body","\n    \n        \n        \n\n        \n        \n\n        \n\n        \n        \n\n        \n\n        \n\n            \n                \n                \n                    \n                        "],["body","\n                            \n                        "],["body","\n                        "],["body","\n                            \n                        "],["body","\n                        \n                            "],["body","Light"],["body","\n                            "],["body","Rust"],["body","\n                            "],["body","Coal"],["body","\n                            "],["body","Navy"],["body","\n                            "],["body","Ayu"],["body","\n                        \n                    \n\n                    "],["heading","AI笔记"],["body","\n\n                    \n\n                    \n                \n\n\n                \n                \n\n                \n                    "],["body","\n                        \n\n"],["body","\n"],["body","\n\n"],["headingLink","记忆模块"],["heading","记忆模块"],["body","\n"],["body","[TOC]"],["body","\n"],["body","LangChain 记忆模块"],["body","\n\n\n\n                    "],["body","\n\n                    \n                \n            \n\n            \n\n        \n\n\n\n\n        \n\n\n\n        \n        \n        \n\n        \n\n\n    \n    \n\n"]],[["_relative_fp","toc.html"],["body","\n        "],["body","0. AI使用场景整理.md"],["body","1. AI资源整理.md"],["body","2. languagechain❱"],["body","2.0. prompts.md"],["body","2.1. memory.md"],["body","3. 可配置的运行块.md"],["body","4. 大模型技术点梳理.md"],["body","\n    \n\n"]],[["_relative_fp","大模型技术点梳理.html"],["title","大模型技术点梳理.md - AI笔记"],["body","\n    \n        \n        \n\n        \n        \n\n        \n\n        \n        \n\n        \n\n        \n\n            \n                \n                \n                    \n                        "],["body","\n                            \n                        "],["body","\n                        "],["body","\n                            \n                        "],["body","\n                        \n                            "],["body","Light"],["body","\n                            "],["body","Rust"],["body","\n                            "],["body","Coal"],["body","\n                            "],["body","Navy"],["body","\n                            "],["body","Ayu"],["body","\n                        \n                    \n\n                    "],["heading","AI笔记"],["body","\n\n                    \n\n                    \n                \n\n\n                \n                \n\n                \n                    "],["body","\n                        \n\n"],["body","\n"],["body","\n\n"],["headingLink","文档解析"],["heading","文档解析"],["body","\n"],["headingLink","文档拆分"],["heading","文档拆分"],["body","\n"],["headingLink","文档向量化"],["heading","文档向量化"],["body","\n"],["headingLink","文档搜索"],["heading","文档搜索"],["body","\n"],["headingLink","agent"],["heading","AGENT"],["body","\n"],["headingLink","function-call"],["heading","Function CALL"],["body","\n\n\n\n                    "],["body","\n\n                    \n                \n            \n\n            \n\n        \n\n\n\n\n        \n\n\n\n        \n        \n        \n\n        \n\n\n    \n    \n\n"]]]